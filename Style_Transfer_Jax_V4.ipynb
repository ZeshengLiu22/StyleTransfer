{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcogxOKjDV3i"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/matthias-wright/flaxmodels.git\n",
        "!pip install optax\n",
        "!git clone https://github.com/MarcoForte/closed-form-matting.git\n",
        "import os\n",
        "os.chdir('closed-form-matting')\n",
        "!pip3 install .\n",
        "os.chdir('..')\n",
        "!pip install jaxopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9Q6oc0PUEXRw"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flaxmodels as fm\n",
        "import matplotlib.pyplot as plt\n",
        "from jax import jit, random, grad\n",
        "import numpy as np\n",
        "import optax\n",
        "from functools import partial\n",
        "from tqdm import trange\n",
        "from jax.example_libraries import optimizers\n",
        "from closed_form_matting import compute_laplacian\n",
        "from jax.experimental import sparse\n",
        "import jaxopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".XX\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\""
      ],
      "metadata": {
        "id": "IOGGzB4CPqtV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOdkjSc7zMVc"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS2Bfjhwk_bx"
      },
      "outputs": [],
      "source": [
        "!wget https://pytorch.org/tutorials/_static/img/neural-style/picasso.jpg\n",
        "!wget https://pytorch.org/tutorials/_static/img/neural-style/dancing.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4N-dUUSEPSA"
      },
      "outputs": [],
      "source": [
        "# Load image\n",
        "img_con = Image.open('dancing.jpg').resize((256,256))\n",
        "display(img_con)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqX-EWVVHfWv"
      },
      "outputs": [],
      "source": [
        "img_sty = Image.open('picasso.jpg').resize((256,256))\n",
        "display(img_sty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mv2R2EwyJJhH"
      },
      "outputs": [],
      "source": [
        "# Image should be in range [0, 1]\n",
        "image_content = jnp.array(img_con, dtype=jnp.float32) / 255.0\n",
        "\n",
        "# Add batch dimension\n",
        "img_content = jnp.expand_dims(image_content, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "n3AmpHGTJYBS"
      },
      "outputs": [],
      "source": [
        "image_style = jnp.array(img_sty, dtype=jnp.float32) / 255\n",
        "\n",
        "img_style = jnp.expand_dims(image_style, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vnhGEadnMTLj"
      },
      "outputs": [],
      "source": [
        "class StyleTransfer:\n",
        "  def __init__(self, input_content, input_style, content_layers, style_layers):\n",
        "    # Original style and content input\n",
        "    self.origin_content = input_content\n",
        "    self.origin_style = input_style\n",
        "\n",
        "    # Initialize Pretrained model\n",
        "    self.vgg19 = fm.VGG19(output='activations', pretrained='imagenet', include_head=False) #flaxmodel on github\n",
        "    self.init_rngs = {'params': jax.random.PRNGKey(0)}#, 'dropout': jax.random.PRNGKey(1)}\n",
        "    self.vggparams = self.vgg19.init(self.init_rngs, img_content)\n",
        "    self.fn_out = jit(self.vgg19.apply)\n",
        "\n",
        "    # Get VGG activation of original style and content input\n",
        "    self.activation_style_origin = self.fn_out(self.vggparams, self.origin_style, train=False)\n",
        "    self.activation_content_origin = self.fn_out(self.vggparams, self.origin_content, train=False)\n",
        "\n",
        "    # Initialize style layer and content layer\n",
        "    self.layer_style = style_layers\n",
        "    self.layer_content = content_layers\n",
        "\n",
        "    #Initialize style and content weights\n",
        "    self.style_weight = 1000000\n",
        "    self.content_weight = 1\n",
        "    self.photo_weight = 100\n",
        "    self.tv_weight = 0.01\n",
        "\n",
        "    # Initialize Optimizer\n",
        "    self.lr = 1e-2\n",
        "    self.optimizer = optax.adam(learning_rate = self.lr) #optax google it \n",
        "\n",
        "    # Initialize generated image\n",
        "    self.generate_img = self.origin_content.copy()\n",
        "    self.opt_state = self.optimizer.init(self.generate_img)\n",
        "\n",
        "    # Matting Laplacian of content image\n",
        "    self.mat_laplacian = sparse.BCOO.from_scipy_sparse(compute_laplacian(self.origin_content[0]))\n",
        "\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def gram_matrix(self, input):\n",
        "    input = jnp.transpose(input, axes=(0, 3, 1, 2)) #N C H W/ N H W C\n",
        "    a, b, c, d = input.shape #a=1, batchsize, b=3 number of feature maps, (c,d) size of feature map\n",
        "    features = input.reshape(a * b, c * d)\n",
        "    G = jnp.matmul(features, features.T)\n",
        "    return G / (a * b * c * d)\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def content_loss(self, input_content, img_generated):\n",
        "    return jnp.mean((input_content.flatten()-img_generated.flatten()) ** 2)\n",
        "  \n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def style_loss(self, input_style, img_generated):\n",
        "    return jnp.mean((input_style - img_generated) ** 2)\n",
        "  \n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def photo_regularization(self, img_generated):\n",
        "    _, h, w, c = img_generated.shape\n",
        "    V_c = img_generated.copy().reshape((h*w, c))\n",
        "    regularization = jnp.trace(V_c.T @ self.mat_laplacian @ V_c)\n",
        "    return regularization\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def tv_loss(self, img_generated):\n",
        "    tv_h = jnp.mean(jnp.abs(img_generated[:, :, 1:, :]-img_generated[:, :, :-1, :]))\n",
        "    tv_w = jnp.mean(jnp.abs(img_generated[:, :, :, 1:]-img_generated[:, :, :, :-1]))\n",
        "    return tv_h+tv_w\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def loss(self, img_generated):\n",
        "    out_generated = self.fn_out(self.vggparams, img_generated, train=False)\n",
        "    \n",
        "    style_score = 0\n",
        "    content_score = 0\n",
        "    photo_score = 0\n",
        "    tv_score = 0\n",
        "\n",
        "    for cont_layer in self.layer_content:\n",
        "      content_score += self.content_loss(self.activation_content_origin[cont_layer], out_generated[cont_layer])\n",
        "    \n",
        "    for sty_layer in self.layer_style:\n",
        "      gram_sty = self.gram_matrix(self.activation_style_origin[sty_layer])\n",
        "      gram_gen = self.gram_matrix(out_generated[sty_layer])\n",
        "      style_score += self.style_loss(gram_sty, gram_gen)\n",
        "    \n",
        "    photo_score = self.photo_regularization(img_generated)\n",
        "\n",
        "    tv_score = self.tv_loss(img_generated)\n",
        "    \n",
        "    loss = self.style_weight * style_score + self.content_weight * content_score\\\n",
        "            + self.photo_weight * photo_score + self.tv_weight * tv_score\n",
        "    return loss\n",
        "  \n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def step(self, optimizer_state, img_generated):\n",
        "    grads = grad(self.loss)(img_generated)\n",
        "    updates, opt_state = self.optimizer.update(grads, optimizer_state, img_generated)\n",
        "    return optax.apply_updates(img_generated, updates), opt_state\n",
        "\n",
        "  def train(self, iter = 8000):\n",
        "    for iter in trange(iter):\n",
        "      self.generate_img, self.opt_state = self.step(self.opt_state, self.generate_img)\n",
        "      self.generate_img = jnp.clip(self.generate_img, 0, 1)\n",
        "    \n",
        "    return self.generate_img\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "A4mgB4z9UcVB"
      },
      "outputs": [],
      "source": [
        "content_layers_default = ['conv4_2']\n",
        "style_layers_default = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
        "sty_trans = StyleTransfer(img_content, img_style, content_layers_default, style_layers_default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iylsf4q3T6W2"
      },
      "outputs": [],
      "source": [
        "output = sty_trans.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6dBA8BgkCK6"
      },
      "outputs": [],
      "source": [
        "img_output = np.array(output[0]*255).astype('uint8')\n",
        "img_out = Image.fromarray(img_output)\n",
        "display(img_out)\n",
        "Image.Image.save(img_out, fp='Right1.jpg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "Wg-5eCXuI5oQ",
        "ayl3Lv41I8HU",
        "dpyNrDh5SXI9"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}